{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from satisfaction_score_data_generator import generate_dataset_with_sensor_readings_and_satisfaction_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82574806]\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5\n",
    "noise_standard_deviation = 0.08\n",
    "wavelet = 'db8'\n",
    "\n",
    "satisfaction_vs_sensors, satisfaction_vs_sensors_null = generate_dataset_with_sensor_readings_and_satisfaction_scores(sample_size, noise_standard_deviation, wavelet)\n",
    "\n",
    "measurement_name = 'air'\n",
    "sensor_name = f'sensor_{measurement_name}'\n",
    "score_name = f'comfort_score_{measurement_name}'\n",
    "\n",
    "score_values = satisfaction_vs_sensors[[score_name]]\n",
    "score_values_null = satisfaction_vs_sensors_null[[score_name]]\n",
    "\n",
    "t_statistics, p_value_t = ttest_ind(score_values, score_values_null)\n",
    "\n",
    "print(p_value_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "sample_size = 10\n",
    "noise_standard_deviation = 0.08\n",
    "measurement_name = 'air'\n",
    "\n",
    "def test_hypothesis(sample_size, alpha, noise_standard_deviation, measurement_name):\n",
    "\n",
    "    satisfaction_vs_sensors, satisfaction_vs_sensors_null = generate_dataset_with_sensor_readings_and_satisfaction_scores(sample_size,                                                                                     noise_standard_deviation, 'db8')\n",
    "\n",
    "    score_name = f'comfort_score_{measurement_name}'\n",
    "\n",
    "    score_values = satisfaction_vs_sensors[[score_name]]\n",
    "    score_values_null = satisfaction_vs_sensors_null[[score_name]]\n",
    "\n",
    "    t_statistics, p_value_t = ttest_ind(score_values, score_values_null)\n",
    "\n",
    "    result = p_value_t < alpha\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = test_hypothesis(sample_size, alpha, noise_standard_deviation, measurement_name)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 250]\n",
    "number_of_experiments = 1000\n",
    "\n",
    "def power_simulation_testing(number_of_experiments, sample_size, alpha, noise_standard_deviation, measurement_name):\n",
    "    rejections = np.zeros(number_of_experiments, dtype=bool)\n",
    "    test_power = []\n",
    "    for size in tqdm(sample_size):\n",
    "        for experiment in range(number_of_experiments):\n",
    "            rejections[experiment] = test_hypothesis(size, alpha, noise_standard_deviation, measurement_name)\n",
    "            \n",
    "        test_power.append(np.mean(rejections))\n",
    "        \n",
    "        \n",
    "    return test_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_power = power_simulation_testing(number_of_experiments, sample_size, alpha, noise_standard_deviation,\n",
    "                                      measurement_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_power' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ef361aa1ea00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Plot test power\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_power\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Power vs Sample Size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sample Size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_power' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot test power\n",
    "plt.plot(sample_size, test_power, 'o-')\n",
    "plt.title('Test Power vs Sample Size')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Test power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
